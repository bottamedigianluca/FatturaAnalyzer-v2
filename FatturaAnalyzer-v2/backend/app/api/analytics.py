"""
Analytics API COMPLETA - Versione Finale
Espone TUTTE le funzionalitÃ  di analisi del core tramite l'adapter completo
Circa 1000+ righe vs 600 dell'originale
"""

import logging
from typing import List, Optional
from datetime import datetime, date
from fastapi import APIRouter, HTTPException, Query, Path
from fastapi.responses import JSONResponse, FileResponse
import pandas as pd

# Uso dell'adapter COMPLETO
from app.adapters.analytics_adapter import analytics_adapter
from app.adapters.database_adapter import db_adapter
from app.models import APIResponse

logger = logging.getLogger(__name__)
router = APIRouter()

# ===== ENDPOINT DASHBOARD (BASE E AVANZATE) =====

@router.get("/dashboard")
async def get_dashboard_data():
    """Dashboard base migliorata con KPI avanzati"""
    try:
        dashboard_data = await analytics_adapter.get_dashboard_data_async()
        
        recent_invoices_query = """
            SELECT i.id, i.type, i.doc_number, i.doc_date, i.total_amount,
                   i.payment_status, i.due_date, a.denomination as counterparty_name,
                   (i.total_amount - i.paid_amount) as open_amount
            FROM Invoices i
            JOIN Anagraphics a ON i.anagraphics_id = a.id
            ORDER BY i.created_at DESC
            LIMIT 10
        """
        
        recent_transactions_query = """
            SELECT id, transaction_date, amount, description, reconciliation_status,
                   (amount - reconciled_amount) as remaining_amount
            FROM BankTransactions
            WHERE reconciliation_status != 'Ignorato'
            ORDER BY transaction_date DESC, id DESC
            LIMIT 10
        """
        
        recent_invoices = await db_adapter.execute_query_async(recent_invoices_query)
        recent_transactions = await db_adapter.execute_query_async(recent_transactions_query)
        
        dashboard_data.update({
            'recent_invoices': recent_invoices,
            'recent_transactions': recent_transactions
        })
        
        return APIResponse(
            success=True,
            message="Dashboard data retrieved successfully",
            data=dashboard_data
        )
        
    except Exception as e:
        logger.error(f"Error getting dashboard data: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving dashboard data")

@router.get("/dashboard/executive")
async def get_executive_dashboard():
    """ðŸ”¥ NUOVO: Dashboard executive con insights automatici"""
    try:
        executive_data = await analytics_adapter.get_executive_dashboard_async()
        
        return APIResponse(
            success=True,
            message="Executive dashboard data retrieved",
            data=executive_data
        )
        
    except Exception as e:
        logger.error(f"Error getting executive dashboard: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving executive dashboard")

@router.get("/dashboard/operations")
async def get_operations_dashboard():
    """ðŸ”¥ NUOVO: Dashboard operativa per gestione quotidiana"""
    try:
        operations_data = await analytics_adapter.get_operations_dashboard_async()
        
        return APIResponse(
            success=True,
            message="Operations dashboard data retrieved",
            data=operations_data
        )
        
    except Exception as e:
        logger.error(f"Error getting operations dashboard: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving operations dashboard")

@router.get("/dashboard/financial")
async def get_financial_dashboard():
    """ðŸ”¥ NUOVO: Dashboard finanziario completo"""
    try:
        # Raccoglie dati finanziari da multiple fonti
        kpis = await analytics_adapter.get_dashboard_kpis_async()
        profitability_df = await analytics_adapter.get_monthly_revenue_costs_async()
        cash_flow_df = await analytics_adapter.get_advanced_cashflow_analysis_async()
        payment_behavior = await analytics_adapter.get_payment_behavior_analysis_async()
        
        financial_data = {
            'kpis': kpis,
            'profitability_trends': profitability_df.to_dict('records') if not profitability_df.empty else [],
            'cash_flow_analysis': cash_flow_df.to_dict('records') if not cash_flow_df.empty else [],
            'payment_behavior': payment_behavior
        }
        
        return APIResponse(
            success=True,
            message="Financial dashboard data retrieved",
            data=financial_data
        )
        
    except Exception as e:
        logger.error(f"Error getting financial dashboard: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving financial dashboard")

# ===== KPI E METRICHE BASE =====

@router.get("/kpis")
async def get_kpis():
    """KPI avanzati per business frutta/verdura"""
    try:
        kpis = await analytics_adapter.get_dashboard_kpis_async()
        return APIResponse(
            success=True,
            message="Advanced KPIs calculated successfully",
            data=kpis
        )
        
    except Exception as e:
        logger.error(f"Error getting KPIs: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error calculating KPIs")

@router.get("/kpis/detailed")
async def get_detailed_kpis():
    """ðŸ”¥ NUOVO: KPI dettagliati con breakdown per categoria"""
    try:
        base_kpis = await analytics_adapter.get_dashboard_kpis_async()
        
        # Aggiungi KPI specifici per frutta/verdura
        seasonal_df = await analytics_adapter.get_seasonal_product_analysis_async('all', 1)
        waste_data = await analytics_adapter.get_waste_and_spoilage_analysis_async()
        inventory_df = await analytics_adapter.get_inventory_turnover_analysis_async()
        
        # Calcola KPI aggiuntivi
        current_month_seasonal = seasonal_df[seasonal_df['month_num'] == str(datetime.now().month)] if not seasonal_df.empty else pd.DataFrame()
        peak_products = current_month_seasonal.nlargest(5, 'total_value')['normalized_product'].tolist() if not current_month_seasonal.empty else []
        
        high_waste_products = waste_data.get('high_waste_products', []) if waste_data else []
        slow_moving = inventory_df[inventory_df['turnover_category'] == 'Lento'].head(5)['normalized_product'].tolist() if not inventory_df.empty else []
        
        detailed_kpis = {
            **base_kpis,
            'seasonal_insights': {
                'peak_products_this_month': peak_products,
                'high_waste_products': high_waste_products,
                'slow_moving_products': slow_moving
            }
        }
        
        return APIResponse(
            success=True,
            message="Detailed KPIs with business insights",
            data=detailed_kpis
        )
        
    except Exception as e:
        logger.error(f"Error getting detailed KPIs: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error calculating detailed KPIs")

# ===== ANALISI PROFITTABILITÃ€ =====

@router.get("/profitability/monthly")
async def get_monthly_profitability(
    start_date: Optional[str] = Query(None, description="Data inizio (YYYY-MM-DD)"),
    end_date: Optional[str] = Query(None, description="Data fine (YYYY-MM-DD)")
):
    """ðŸ”¥ NUOVO: Analisi margini di profitto mensili"""
    try:
        profitability_df = await analytics_adapter.get_monthly_revenue_costs_async(start_date, end_date)
        profitability_data = profitability_df.to_dict('records') if not profitability_df.empty else []
        
        return APIResponse(
            success=True,
            message="Monthly profitability analysis completed",
            data=profitability_data
        )
        
    except Exception as e:
        logger.error(f"Error getting monthly profitability: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving profitability analysis")

@router.get("/profitability/breakdown")
async def get_profitability_breakdown(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """ðŸ”¥ NUOVO: Breakdown dettagliato profittabilitÃ  per categoria"""
    try:
        # Analisi per frutta vs verdura
        fruit_seasonal = await analytics_adapter.get_seasonal_product_analysis_async('frutta', 1)
        vegetable_seasonal = await analytics_adapter.get_seasonal_product_analysis_async('verdura', 1)
        
        # Analisi competitiva per margini
        competitive_df = await analytics_adapter.get_competitive_analysis_async()
        
        breakdown_data = {
            'fruit_performance': fruit_seasonal.to_dict('records') if not fruit_seasonal.empty else [],
            'vegetable_performance': vegetable_seasonal.to_dict('records') if not vegetable_seasonal.empty else [],
            'margin_analysis': competitive_df.to_dict('records') if not competitive_df.empty else []
        }
        
        return APIResponse(
            success=True,
            message="Profitability breakdown by category completed",
            data=breakdown_data
        )
        
    except Exception as e:
        logger.error(f"Error getting profitability breakdown: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving profitability breakdown")

# ===== ANALISI STAGIONALITÃ€ =====

@router.get("/seasonality/products")
async def get_product_seasonality(
    product_category: str = Query("all", description="Categoria: all, frutta, verdura"),
    years_back: int = Query(3, ge=1, le=10, description="Anni di storico da analizzare")
):
    """ðŸ”¥ NUOVO: Analisi stagionalitÃ  prodotti - ORO per frutta/verdura!"""
    try:
        seasonal_df = await analytics_adapter.get_seasonal_product_analysis_async(product_category, years_back)
        seasonal_data = seasonal_df.to_dict('records') if not seasonal_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Seasonal analysis for {product_category} products completed",
            data={
                'category': product_category,
                'years_analyzed': years_back,
                'seasonal_patterns': seasonal_data
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting product seasonality: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving seasonal analysis")

@router.get("/seasonality/forecast")
async def get_seasonal_forecast(
    product_category: str = Query("all", description="Categoria prodotti"),
    months_ahead: int = Query(6, ge=1, le=12, description="Mesi da prevedere")
):
    """ðŸ”¥ NUOVO: Previsioni basate su stagionalitÃ """
    try:
        # Combina analisi stagionale con forecast
        seasonal_df = await analytics_adapter.get_seasonal_product_analysis_async(product_category, 3)
        
        forecast_data = []
        if not seasonal_df.empty:
            # Per ogni mese futuro, prevedi basandosi su patterns stagionali
            current_month = datetime.now().month
            for i in range(months_ahead):
                future_month = ((current_month + i - 1) % 12) + 1
                month_str = f"{future_month:02d}"
                
                month_products = seasonal_df[seasonal_df['month_num'] == month_str]
                if not month_products.empty:
                    top_products = month_products.nlargest(10, 'seasonality_index')
                    forecast_data.append({
                        'month': future_month,
                        'month_name': datetime(2024, future_month, 1).strftime('%B'),
                        'predicted_top_products': top_products[['normalized_product', 'seasonality_index', 'total_value']].to_dict('records')
                    })
        
        return APIResponse(
            success=True,
            message=f"Seasonal forecast for {months_ahead} months",
            data={
                'category': product_category,
                'months_ahead': months_ahead,
                'forecast': forecast_data
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting seasonal forecast: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving seasonal forecast")

# ===== ANALISI CLIENTI =====

@router.get("/clients/performance")
async def get_clients_performance(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine"),
    limit: int = Query(20, ge=1, le=100, description="Numero clienti")
):
    """ðŸ”¥ NUOVO: Analisi performance clienti AVANZATA con segmentazione"""
    try:
        performance_df = await analytics_adapter.get_top_clients_performance_async(start_date, end_date, limit)
        performance_data = performance_df.to_dict('records') if not performance_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Advanced client performance analysis for {len(performance_data)} clients",
            data=performance_data
        )
        
    except Exception as e:
        logger.error(f"Error getting client performance: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving client performance")

@router.get("/clients/top")
async def get_top_clients(
    limit: int = Query(20, ge=1, le=100, description="Number of top clients"),
    period_months: int = Query(12, ge=1, le=60, description="Analysis period in months"),
    min_revenue: Optional[float] = Query(None, description="Minimum revenue filter")
):
    """Get top clients by revenue using adapter"""
    try:
        clients_df = await analytics_adapter.get_top_clients_by_revenue_async(limit, period_months, min_revenue)
        clients_data = clients_df.to_dict('records') if not clients_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Top {len(clients_data)} clients by revenue",
            data=clients_data
        )
        
    except Exception as e:
        logger.error(f"Error getting top clients: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving top clients")

@router.get("/clients/by-score")
async def get_clients_by_score(
    order: str = Query("DESC", description="Ordine: ASC o DESC"),
    limit: int = Query(20, ge=1, le=100, description="Numero clienti")
):
    """Clienti ordinati per score con informazioni dettagliate"""
    try:
        clients_df = await analytics_adapter.get_clients_by_score_async(order, limit)
        clients_data = clients_df.to_dict('records') if not clients_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Clients by score retrieved ({order} order)",
            data=clients_data
        )
        
    except Exception as e:
        logger.error(f"Error getting clients by score: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving clients by score")

@router.get("/clients/{anagraphics_id}/financial-summary")
async def get_client_financial_summary(anagraphics_id: int):
    """Get financial summary for specific client"""
    try:
        summary = await analytics_adapter.get_anagraphic_financial_summary_async(anagraphics_id)
        
        return APIResponse(
            success=True,
            message=f"Financial summary for client {anagraphics_id}",
            data=summary
        )
        
    except Exception as e:
        logger.error(f"Error getting client financial summary: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving client financial summary")

@router.get("/clients/{anagraphics_id}/detailed")
async def get_client_detailed_analysis(anagraphics_id: int):
    """ðŸ”¥ NUOVO: Analisi dettagliata cliente con insights"""
    try:
        # Sommario finanziario base
        summary = await analytics_adapter.get_anagraphic_financial_summary_async(anagraphics_id)
        
        # Prodotti preferiti (market basket per questo cliente)
        market_basket = await analytics_adapter.get_market_basket_analysis_async()
        
        # Comportamento pagamenti di questo cliente
        payment_behavior = await analytics_adapter.get_payment_behavior_analysis_async()
        client_payment_data = None
        if payment_behavior and 'client_behavior' in payment_behavior:
            client_payment_data = payment_behavior['client_behavior']
            client_payment_data = client_payment_data[client_payment_data['id'] == anagraphics_id].to_dict('records')
            client_payment_data = client_payment_data[0] if client_payment_data else None
        
        detailed_analysis = {
            'financial_summary': summary,
            'payment_behavior': client_payment_data,
            'preferred_products': summary.get('preferred_products', []),
            'risk_assessment': {
                'payment_risk': 'Alto' if client_payment_data and client_payment_data.get('avg_delay', 0) > 15 else 'Basso',
                'churn_risk': 'Alto' if summary.get('customer_segment') == 'Inactive' else 'Basso'
            }
        }
        
        return APIResponse(
            success=True,
            message=f"Detailed analysis for client {anagraphics_id}",
            data=detailed_analysis
        )
        
    except Exception as e:
        logger.error(f"Error getting detailed client analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving detailed client analysis")

@router.get("/clients/scores/update")
async def update_client_scores():
    """Update client scores using adapter"""
    try:
        success = await analytics_adapter.calculate_and_update_client_scores_async()
        
        return APIResponse(
            success=success,
            message="Client scores updated successfully" if success else "Failed to update client scores",
            data={"updated": success}
        )
        
    except Exception as e:
        logger.error(f"Error updating client scores: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error updating client scores")

# ===== SEGMENTAZIONE E RFM =====

@router.get("/customers/rfm")
async def get_customer_rfm(
    analysis_date: Optional[str] = Query(None, description="Data di riferimento per l'analisi (YYYY-MM-DD)")
):
    """ðŸ”¥ NUOVO: Segmentazione RFM avanzata (Champions, At Risk, etc.)"""
    try:
        rfm_data = await analytics_adapter.get_customer_rfm_analysis_async(analysis_date)
        
        return APIResponse(
            success=True,
            message="RFM customer segmentation completed",
            data=rfm_data
        )
        
    except Exception as e:
        logger.error(f"Error getting RFM analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving RFM analysis")

@router.get("/customers/churn-risk")
async def get_churn_risk():
    """ðŸ”¥ NUOVO: Analisi rischio abbandono clienti con azioni suggerite"""
    try:
        churn_df = await analytics_adapter.get_customer_churn_analysis_async()
        churn_data = churn_df.to_dict('records') if not churn_df.empty else []
        
        # Raggruppa per categoria di rischio
        risk_summary = {}
        for customer in churn_data:
            risk_cat = customer.get('risk_category', 'Unknown')
            if risk_cat not in risk_summary:
                risk_summary[risk_cat] = 0
            risk_summary[risk_cat] += 1
        
        return APIResponse(
            success=True,
            message="Customer churn risk analysis completed",
            data={
                'customers': churn_data,
                'risk_summary': risk_summary,
                'total_analyzed': len(churn_data)
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting churn analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving churn analysis")

@router.get("/segmentation/clients")
async def get_client_segmentation(
    segmentation_type: str = Query("revenue", description="Segmentation type: revenue, frequency, recency"),
    period_months: int = Query(12, ge=1, le=60, description="Analysis period in months")
):
    """Get client segmentation analysis"""
    try:
        segmentation_data = await analytics_adapter.get_client_segmentation_async(
            segmentation_type, period_months
        )
        
        return APIResponse(
            success=True,
            message=f"Client segmentation by {segmentation_type}",
            data={
                'segmentation_type': segmentation_type,
                'period_months': period_months,
                'segments': segmentation_data
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting client segmentation: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error generating client segmentation")

# ===== ANALISI FORNITORI =====

@router.get("/suppliers/analysis")
async def get_supplier_analysis(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """ðŸ”¥ NUOVO: Analisi fornitori con reliability score"""
    try:
        suppliers_df = await analytics_adapter.get_supplier_analysis_async(start_date, end_date)
        suppliers_data = suppliers_df.to_dict('records') if not suppliers_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Supplier analysis completed for {len(suppliers_data)} suppliers",
            data=suppliers_data
        )
        
    except Exception as e:
        logger.error(f"Error getting supplier analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving supplier analysis")

@router.get("/suppliers/top-by-cost")
async def get_top_suppliers(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine"),
    limit: int = Query(20, ge=1, le=100, description="Numero fornitori")
):
    """Top fornitori per costo con metriche performance"""
    try:
        suppliers_df = await analytics_adapter.get_top_suppliers_by_cost_async(start_date, end_date, limit)
        suppliers_data = suppliers_df.to_dict('records') if not suppliers_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Top {len(suppliers_data)} suppliers by cost",
            data=suppliers_data
        )
        
    except Exception as e:
        logger.error(f"Error getting top suppliers: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving top suppliers")

@router.get("/suppliers/reliability")
async def get_supplier_reliability():
    """ðŸ”¥ NUOVO: Focus su affidabilitÃ  fornitori"""
    try:
        suppliers_df = await analytics_adapter.get_supplier_analysis_async()
        
        if not suppliers_df.empty:
            # Raggruppa per tier di affidabilitÃ 
            reliability_summary = suppliers_df.groupby('supplier_tier').agg({
                'total_cost': 'sum',
                'reliability_score': 'mean',
                'supplier_tier': 'count'
            }).rename(columns={'supplier_tier': 'count'}).to_dict('index')
            
            # Identifica fornitori critici (bassa affidabilitÃ , alto volume)
            critical_suppliers = suppliers_df[
                (suppliers_df['supplier_tier'].isin(['Basic', 'Good'])) & 
                (suppliers_df['total_cost'] > suppliers_df['total_cost'].median())
            ].to_dict('records')
            
        else:
            reliability_summary = {}
            critical_suppliers = []
        
        return APIResponse(
            success=True,
            message="Supplier reliability analysis completed",
            data={
                'reliability_summary': reliability_summary,
                'critical_suppliers': critical_suppliers,
                'all_suppliers': suppliers_df.to_dict('records') if not suppliers_df.empty else []
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting supplier reliability: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving supplier reliability")

# ===== ANALISI PRODOTTI E INVENTARIO =====

@router.get("/products/analysis")
async def get_product_analysis(
    limit: int = Query(50, ge=1, le=200, description="Number of top products"),
    period_months: int = Query(12, ge=1, le=60, description="Analysis period in months"),
    min_quantity: Optional[float] = Query(None, description="Minimum quantity filter"),
    invoice_type: Optional[str] = Query(None, description="Filter by invoice type")
):
    """Get product analysis using adapter"""
    try:
        products_df = await analytics_adapter.get_product_analysis_async(
            limit, period_months, min_quantity, invoice_type
        )
        products_data = products_df.to_dict('records') if not products_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Product analysis for {len(products_data)} items",
            data=products_data
        )
        
    except Exception as e:
        logger.error(f"Error getting product analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving product analysis")

@router.get("/products/{normalized_description}/monthly-sales")
async def get_product_monthly_sales(
    normalized_description: str = Path(..., description="Descrizione normalizzata del prodotto"),
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """Vendite mensili prodotto specifico con trend"""
    try:
        sales_df = await analytics_adapter.get_product_monthly_sales_async(
            normalized_description, start_date, end_date
        )
        sales_data = sales_df.to_dict('records') if not sales_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Monthly sales for '{normalized_description}' retrieved",
            data={
                'product': normalized_description,
                'monthly_sales': sales_data
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting product monthly sales: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving product monthly sales")

@router.get("/products/{normalized_description}/comparison")
async def get_product_comparison(
    normalized_description: str = Path(..., description="Descrizione normalizzata del prodotto"),
    year1: int = Query(..., description="Primo anno da confrontare"),
    year2: int = Query(..., description="Secondo anno da confrontare")
):
    """Confronto vendite prodotto tra due anni"""
    try:
        comparison_df = await analytics_adapter.get_product_sales_comparison_async(
            normalized_description, year1, year2
        )
        comparison_data = comparison_df.to_dict('records') if not comparison_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Sales comparison for '{normalized_description}' ({year1} vs {year2})",
            data={
                'product': normalized_description,
                'year1': year1,
                'year2': year2,
                'comparison': comparison_data
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting product comparison: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving product comparison")

@router.get("/waste/analysis")
async def get_waste_analysis(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """ðŸ”¥ NUOVO: Analisi scarti e deterioramento - CRITICA per prodotti freschi!"""
    try:
        waste_data = await analytics_adapter.get_waste_and_spoilage_analysis_async(start_date, end_date)
        
        return APIResponse(
            success=True,
            message="Waste and spoilage analysis completed",
            data=waste_data
        )
        
    except Exception as e:
        logger.error(f"Error getting waste analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving waste analysis")

@router.get("/inventory/turnover")
async def get_inventory_turnover(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """ðŸ”¥ NUOVO: Analisi rotazione inventario per prodotti deperibili"""
    try:
        turnover_df = await analytics_adapter.get_inventory_turnover_analysis_async(start_date, end_date)
        turnover_data = turnover_df.to_dict('records') if not turnover_df.empty else []
        
        return APIResponse(
            success=True,
            message="Inventory turnover analysis completed",
            data=turnover_data
        )
        
    except Exception as e:
        logger.error(f"Error getting inventory turnover: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving inventory turnover")

@router.get("/inventory/alerts")
async def get_inventory_alerts():
    """ðŸ”¥ NUOVO: Alert inventario per prodotti critici"""
    try:
        turnover_df = await analytics_adapter.get_inventory_turnover_analysis_async()
        waste_data = await analytics_adapter.get_waste_and_spoilage_analysis_async()
        
        alerts = []
        
        if not turnover_df.empty:
            # Prodotti a rotazione lenta
            slow_products = turnover_df[turnover_df['turnover_category'] == 'Lento']
            for _, product in slow_products.iterrows():
                alerts.append({
                    'type': 'slow_moving',
                    'product': product['normalized_product'],
                    'severity': 'medium',
                    'message': f"Prodotto a rotazione lenta: {product['normalized_product']}",
                    'action': 'Considera promozioni o riduzione ordini'
                })
        
        if waste_data and 'high_waste_products' in waste_data:
            for product in waste_data['high_waste_products']:
                alerts.append({
                    'type': 'high_waste',
                    'product': product,
                    'severity': 'high',
                    'message': f"Alto tasso di scarto: {product}",
                    'action': 'Rivedi gestione qualitÃ  e timing ordini'
                })
        
        return APIResponse(
            success=True,
            message=f"Inventory alerts generated: {len(alerts)} issues found",
            data={
                'alerts': alerts,
                'alert_count': len(alerts),
                'critical_count': len([a for a in alerts if a['severity'] == 'high'])
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting inventory alerts: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving inventory alerts")

# ===== ANALISI PREZZI E COMPETITIVITÃ€ =====

@router.get("/pricing/trends")
async def get_price_trends(
    product_name: Optional[str] = Query(None, description="Nome prodotto specifico"),
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """ðŸ”¥ NUOVO: Analisi trend prezzi con volatilitÃ """
    try:
        price_data = await analytics_adapter.get_price_trend_analysis_async(product_name, start_date, end_date)
        
        return APIResponse(
            success=True,
            message=f"Price trend analysis completed{' for ' + product_name if product_name else ''}",
            data=price_data
        )
        
    except Exception as e:
        logger.error(f"Error getting price trends: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving price trends")

@router.get("/competitive/analysis")
async def get_competitive_analysis():
    """ðŸ”¥ NUOVO: Analisi competitiva margini acquisto/vendita"""
    try:
        competitive_df = await analytics_adapter.get_competitive_analysis_async()
        competitive_data = competitive_df.to_dict('records') if not competitive_df.empty else []
        
        return APIResponse(
            success=True,
            message="Competitive analysis completed",
            data=competitive_data
        )
        
    except Exception as e:
        logger.error(f"Error getting competitive analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving competitive analysis")

@router.get("/competitive/opportunities")
async def get_competitive_opportunities():
    """ðŸ”¥ NUOVO: OpportunitÃ  competitive basate sui margini"""
    try:
        competitive_df = await analytics_adapter.get_competitive_analysis_async()
        
        opportunities = []
        if not competitive_df.empty:
            # Prodotti con margini bassi ma buon volume
            low_margin_high_volume = competitive_df[
                (competitive_df['markup_percentage'] < 20) & 
                (competitive_df['market_penetration'] > 70)
            ]
            
            for _, product in low_margin_high_volume.iterrows():
                opportunities.append({
                    'type': 'price_increase',
                    'product': product['normalized_product'],
                    'current_margin': f"{product['markup_percentage']:.1f}%",
                    'opportunity': f"Aumentare prezzo di vendita del 5-10%",
                    'potential_impact': f"Potenziale aumento margine: â‚¬{product['markup_amount'] * 0.1:.2f}/unitÃ "
                })
            
            # Prodotti con fornitori unici (rischio diversificazione)
            single_supplier = competitive_df[competitive_df['supplier_diversification'] == 1]
            for _, product in single_supplier.iterrows():
                opportunities.append({
                    'type': 'supplier_diversification',
                    'product': product['normalized_product'],
                    'risk': 'Dipendenza da singolo fornitore',
                    'opportunity': 'Cercare fornitori alternativi',
                    'potential_impact': 'Riduzione rischio supply chain'
                })
        
        return APIResponse(
            success=True,
            message=f"Competitive opportunities identified: {len(opportunities)}",
            data={
                'opportunities': opportunities,
                'total_opportunities': len(opportunities)
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting competitive opportunities: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving competitive opportunities")

# ===== MARKET BASKET E CROSS-SELLING =====

@router.get("/market-basket/analysis")
async def get_market_basket(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine"),
    min_support: float = Query(0.01, ge=0.001, le=0.5, description="Supporto minimo")
):
    """ðŸ”¥ NUOVO: Market basket analysis per cross-selling"""
    try:
        basket_data = await analytics_adapter.get_market_basket_analysis_async(start_date, end_date, min_support)
        
        return APIResponse(
            success=True,
            message="Market basket analysis completed",
            data=basket_data
        )
        
    except Exception as e:
        logger.error(f"Error getting market basket analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving market basket analysis")

@router.get("/market-basket/recommendations")
async def get_cross_selling_recommendations():
    """ðŸ”¥ NUOVO: Raccomandazioni cross-selling basate su market basket"""
    try:
        basket_data = await analytics_adapter.get_market_basket_analysis_async()
        
        recommendations = []
        if basket_data and 'associations' in basket_data and not basket_data['associations'].empty:
            top_associations = basket_data['associations'].head(10)
            
            for _, assoc in top_associations.iterrows():
                recommendations.append({
                    'product_1': assoc['product_1'],
                    'product_2': assoc['product_2'],
                    'confidence': f"{assoc['confidence_1_2']:.1%}",
                    'lift': f"{assoc['lift']:.2f}",
                    'recommendation': f"Chi compra {assoc['product_1']} spesso compra anche {assoc['product_2']}",
                    'action': f"Posiziona {assoc['product_2']} vicino a {assoc['product_1']} o crea bundle"
                })
        
        return APIResponse(
            success=True,
            message=f"Cross-selling recommendations generated: {len(recommendations)}",
            data={
                'recommendations': recommendations,
                'total_recommendations': len(recommendations)
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting cross-selling recommendations: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving cross-selling recommendations")

# ===== CASH FLOW E ANALISI FINANZIARIE =====

@router.get("/cash-flow/monthly")
async def get_monthly_cash_flow(
    months: int = Query(12, ge=1, le=60, description="Number of months to analyze")
):
    """Get monthly cash flow analysis using adapter"""
    try:
        cash_flow_df = await analytics_adapter.get_monthly_cash_flow_analysis_async(months)
        cash_flow_data = cash_flow_df.to_dict('records') if not cash_flow_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Cash flow data for {months} months",
            data=cash_flow_data
        )
        
    except Exception as e:
        logger.error(f"Error getting monthly cash flow: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving cash flow data")

@router.get("/cash-flow/advanced")
async def get_advanced_cash_flow(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """ðŸ”¥ NUOVO: Cash flow AVANZATO con categorizzazione business"""
    try:
        advanced_cf_df = await analytics_adapter.get_advanced_cashflow_analysis_async(start_date, end_date)
        advanced_cf_data = advanced_cf_df.to_dict('records') if not advanced_cf_df.empty else []
        
        return APIResponse(
            success=True,
            message="Advanced cash flow analysis completed",
            data=advanced_cf_data
        )
        
    except Exception as e:
        logger.error(f"Error getting advanced cash flow: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving advanced cash flow")

@router.get("/forecasting/cash-flow")
async def get_cash_flow_forecast(
    months_ahead: int = Query(6, ge=1, le=24, description="Months to forecast ahead"),
    include_scheduled: bool = Query(True, description="Include scheduled payments from due dates")
):
    """Get cash flow forecasting"""
    try:
        forecast_data = await analytics_adapter.get_cash_flow_forecast_async(
            months_ahead, include_scheduled
        )
        
        return APIResponse(
            success=True,
            message=f"Cash flow forecast for {months_ahead} months",
            data=forecast_data
        )
        
    except Exception as e:
        logger.error(f"Error getting cash flow forecast: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error generating cash flow forecast")

@router.get("/forecasting/sales")
async def get_sales_forecast(
    product_name: Optional[str] = Query(None, description="Nome prodotto specifico"),
    months_ahead: int = Query(3, ge=1, le=12, description="Mesi da prevedere")
):
    """ðŸ”¥ NUOVO: Previsioni vendite basate su trend storici"""
    try:
        forecast_df = await analytics_adapter.get_sales_forecast_async(product_name, months_ahead)
        forecast_data = forecast_df.to_dict('records') if not forecast_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Sales forecast completed for {months_ahead} months ahead",
            data={
                'product': product_name,
                'months_ahead': months_ahead,
                'forecast': forecast_data
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting sales forecast: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving sales forecast")

# ===== ANALISI PAGAMENTI =====

@router.get("/payments/behavior")
async def get_payment_behavior():
    """ðŸ”¥ NUOVO: Analisi comportamentale pagamenti"""
    try:
        behavior_data = await analytics_adapter.get_payment_behavior_analysis_async()
        
        return APIResponse(
            success=True,
            message="Payment behavior analysis completed",
            data=behavior_data
        )
        
    except Exception as e:
        logger.error(f"Error getting payment behavior: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving payment behavior")

@router.get("/performance/payment")
async def get_payment_performance():
    """Get payment performance metrics"""
    try:
        performance_data = await analytics_adapter.get_payment_performance_async()
        
        return APIResponse(
            success=True,
            message="Payment performance metrics retrieved",
            data=performance_data
        )
        
    except Exception as e:
        logger.error(f"Error getting payment performance: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving payment performance")

@router.get("/payments/optimization")
async def get_payment_optimization():
    """ðŸ”¥ NUOVO: Ottimizzazione termini di pagamento"""
    try:
        behavior_data = await analytics_adapter.get_payment_behavior_analysis_async()
        
        optimization_suggestions = []
        
        if behavior_data and 'client_behavior' in behavior_data:
            client_behavior = behavior_data['client_behavior']
            
            # Clienti con ritardi cronici
            chronic_late = client_behavior[client_behavior['behavior_category'] == 'Ritardo Cronico']
            for _, client in chronic_late.iterrows():
                optimization_suggestions.append({
                    'client_id': client['id'],
                    'client_name': client['denomination'],
                    'issue': f"Ritardo medio: {client['avg_delay']:.1f} giorni",
                    'suggestion': 'Ridurre termini di pagamento o richiedere garanzie',
                    'priority': 'alta'
                })
            
            # Analisi giorno della settimana ottimale
            if 'day_analysis' in behavior_data:
                best_day = behavior_data['day_analysis']['mean'].idxmin()
                optimization_suggestions.append({
                    'type': 'general',
                    'suggestion': f"Impostare scadenze preferibilmente di {best_day}",
                    'reason': 'Giorno con minor ritardo medio nei pagamenti',
                    'priority': 'media'
                })
        
        return APIResponse(
            success=True,
            message=f"Payment optimization suggestions: {len(optimization_suggestions)}",
            data={
                'suggestions': optimization_suggestions,
                'total_suggestions': len(optimization_suggestions)
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting payment optimization: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving payment optimization")

# ===== REVENUE E TREND =====

@router.get("/revenue/monthly")
async def get_monthly_revenue(
    months: int = Query(12, ge=1, le=60, description="Number of months to analyze"),
    invoice_type: Optional[str] = Query(None, description="Filter by invoice type: Attiva or Passiva")
):
    """Get monthly revenue analysis using adapter"""
    try:
        revenue_df = await analytics_adapter.get_monthly_revenue_analysis_async(months, invoice_type)
        revenue_data = revenue_df.to_dict('records') if not revenue_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Revenue data for {months} months",
            data=revenue_data
        )
        
    except Exception as e:
        logger.error(f"Error getting monthly revenue: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving revenue data")

@router.get("/trends/revenue")
async def get_revenue_trends(
    period: str = Query("monthly", description="Period: daily, weekly, monthly, quarterly"),
    months_back: int = Query(12, ge=1, le=60, description="Months to look back")
):
    """Get revenue trends analysis using adapter"""
    try:
        trends = await analytics_adapter.get_revenue_trends_async(period, months_back)
        
        return APIResponse(
            success=True,
            message=f"Revenue trends for {period} periods",
            data={
                "trends": trends,
                "period": period,
                "months_analyzed": months_back
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting revenue trends: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving revenue trends")

@router.get("/comparison/year-over-year")
async def get_year_over_year_comparison(
    metric: str = Query("revenue", description="Metric to compare: revenue, profit, volume"),
    current_year: Optional[int] = Query(None, description="Current year (default: current year)")
):
    """Get year-over-year comparison analysis"""
    try:
        comparison_data = await analytics_adapter.get_year_over_year_comparison_async(
            metric, current_year
        )
        
        return APIResponse(
            success=True,
            message=f"Year-over-year {metric} comparison",
            data=comparison_data
        )
        
    except Exception as e:
        logger.error(f"Error getting year-over-year comparison: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error generating year-over-year comparison")

# ===== AGING E FATTURE SCADUTE =====

@router.get("/aging/invoices")
async def get_invoices_aging(
    invoice_type: str = Query("Attiva", description="Invoice type: Attiva or Passiva")
):
    """Get aging analysis for invoices using adapter"""
    try:
        aging_data = await analytics_adapter.get_aging_summary_async(invoice_type)
        
        buckets = []
        total_amount = 0.0
        total_count = 0
        
        for label, data in aging_data.items():
            amount = float(data['amount'])
            count = data['count']
            buckets.append({
                "label": label,
                "amount": amount,
                "count": count
            })
            total_amount += amount
            total_count += count
        
        return APIResponse(
            success=True,
            message=f"Aging analysis for {invoice_type} invoices",
            data={
                "buckets": buckets,
                "total_amount": total_amount,
                "total_count": total_count,
                "invoice_type": invoice_type
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting aging analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving aging analysis")

@router.get("/overdue/invoices")
async def get_overdue_invoices(
    limit: int = Query(20, ge=1, le=100, description="Number of invoices to return"),
    priority_sort: bool = Query(True, description="Sort by priority (amount and days overdue)")
):
    """Get overdue invoices using adapter"""
    try:
        overdue_df = await analytics_adapter.get_top_overdue_invoices_async(limit, priority_sort)
        overdue_data = overdue_df.to_dict('records') if not overdue_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Found {len(overdue_data)} overdue invoices",
            data=overdue_data
        )
        
    except Exception as e:
        logger.error(f"Error getting overdue invoices: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving overdue invoices")

# ===== CALENDARIO E SCADENZE =====

@router.get("/calendar/due-dates/{year}/{month}")
async def get_due_dates_calendar(
    year: int = Path(..., description="Anno"),
    month: int = Path(..., ge=1, le=12, description="Mese")
):
    """Date con scadenze nel mese per calendario"""
    try:
        due_dates = await analytics_adapter.get_due_dates_in_month_async(year, month)
        
        # Converti le date in stringhe per JSON
        due_dates_str = [d.isoformat() for d in due_dates]
        
        return APIResponse(
            success=True,
            message=f"Due dates for {year}-{month:02d} retrieved",
            data={
                'year': year,
                'month': month,
                'due_dates': due_dates_str,
                'count': len(due_dates)
            }
        )
        
    except Exception as e:
        logger.error(f"Error getting due dates calendar: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving due dates calendar")

@router.get("/invoices/due-on/{due_date}")
async def get_invoices_due_on_date(
    due_date: str = Path(..., description="Data scadenza (YYYY-MM-DD)")
):
    """Fatture in scadenza in data specifica"""
    try:
        from datetime import datetime
        due_date_obj = datetime.strptime(due_date, "%Y-%m-%d").date()
        
        invoices_df = await analytics_adapter.get_invoices_due_on_date_async(due_date_obj)
        invoices_data = invoices_df.to_dict('records') if not invoices_df.empty else []
        
        return APIResponse(
            success=True,
            message=f"Invoices due on {due_date} retrieved",
            data={
                'due_date': due_date,
                'invoices': invoices_data,
                'count': len(invoices_data)
            }
        )
        
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD")
    except Exception as e:
        logger.error(f"Error getting invoices due on date: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving invoices due on date")

# ===== COMMISSIONI E COSTI =====

@router.get("/commissions/summary")
async def get_commission_summary(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """Sommario commissioni bancarie dettagliato"""
    try:
        commission_df = await analytics_adapter.get_commission_summary_async(start_date, end_date)
        commission_data = commission_df.to_dict('records') if not commission_df.empty else []
        
        return APIResponse(
            success=True,
            message="Commission summary completed",
            data=commission_data
        )
        
    except Exception as e:
        logger.error(f"Error getting commission summary: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving commission summary")

# ===== BUSINESS INSIGHTS E RACCOMANDAZIONI =====

@router.get("/insights/business")
async def get_business_insights(
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """ðŸ”¥ NUOVO: Insights business con raccomandazioni automatiche"""
    try:
        insights_data = await analytics_adapter.get_business_insights_summary_async(start_date, end_date)
        
        return APIResponse(
            success=True,
            message="Business insights analysis completed",
            data=insights_data
        )
        
    except Exception as e:
        logger.error(f"Error getting business insights: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving business insights")

@router.get("/insights/executive-summary")
async def get_executive_summary():
    """ðŸ”¥ NUOVO: Riepilogo executive con KPI chiave e azioni"""
    try:
        # Raccoglie i dati piÃ¹ importanti
        kpis = await analytics_adapter.get_dashboard_kpis_async()
        churn_df = await analytics_adapter.get_customer_churn_analysis_async()
        waste_data = await analytics_adapter.get_waste_and_spoilage_analysis_async()
        competitive_df = await analytics_adapter.get_competitive_analysis_async()
        
        # Calcola metriche executive
        high_risk_customers = len(churn_df[churn_df['risk_category'] == 'Critico']) if not churn_df.empty else 0
        waste_products_count = len(waste_data.get('high_waste_products', [])) if waste_data else 0
        low_margin_products = len(competitive_df[competitive_df['markup_percentage'] < 15]) if not competitive_df.empty else 0
        
        # Genera azioni prioritarie
        priority_actions = []
        
        if high_risk_customers > 0:
            priority_actions.append({
                'priority': 'alta',
                'area': 'Customer Retention',
                'action': f'Contattare {high_risk_customers} clienti a rischio abbandono',
                'impact': 'Prevenire perdita fatturato'
            })
        
        if waste_products_count > 0:
            priority_actions.append({
                'priority': 'alta',
                'area': 'Operational Efficiency',
                'action': f'Ottimizzare gestione di {waste_products_count} prodotti ad alto scarto',
                'impact': 'Ridurre costi e sprechi'
            })
        
        if low_margin_products > 0:
            priority_actions.append({
                'priority': 'media',
                'area': 'Pricing Strategy',
                'action': f'Rivedere prezzi di {low_margin_products} prodotti a basso margine',
                'impact': 'Aumentare profittabilitÃ '
            })
        
        executive_summary = {
            'period': datetime.now().strftime('%B %Y'),
            'key_metrics': {
                'total_receivables': kpis.get('total_receivables', 0),
                'revenue_ytd': kpis.get('revenue_ytd', 0),
                'margin_percent_ytd': kpis.get('margin_percent_ytd', 0),
                'overdue_receivables_count': kpis.get('overdue_receivables_count', 0)
            },
            'risk_indicators': {
                'high_risk_customers': high_risk_customers,
                'waste_products': waste_products_count,
                'low_margin_products': low_margin_products
            },
            'priority_actions': priority_actions
        }
        
        return APIResponse(
            success=True,
            message="Executive summary generated",
            data=executive_summary
        )
        
    except Exception as e:
        logger.error(f"Error getting executive summary: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error retrieving executive summary")

# ===== EXPORT E REPORTISTICA =====

@router.get("/export/analysis")
async def export_analysis(
    analysis_type: str = Query(..., description="Tipo di analisi da esportare"),
    format: str = Query("excel", description="Formato: excel, csv"),
    start_date: Optional[str] = Query(None, description="Data inizio"),
    end_date: Optional[str] = Query(None, description="Data fine")
):
    """Esporta analisi in formato Excel/CSV"""
    try:
        # Raccoglie i dati basati sul tipo di analisi
        data_to_export = {}
        
        if analysis_type == "seasonal":
            seasonal_df = await analytics_adapter.get_seasonal_product_analysis_async()
            data_to_export['seasonal_analysis'] = seasonal_df
            
        elif analysis_type == "profitability":
            profit_df = await analytics_adapter.get_monthly_revenue_costs_async(start_date, end_date)
            data_to_export['profitability'] = profit_df
            
        elif analysis_type == "customers":
            clients_df = await analytics_adapter.get_top_clients_performance_async(start_date, end_date)
            rfm_data = await analytics_adapter.get_customer_rfm_analysis_async()
            churn_df = await analytics_adapter.get_customer_churn_analysis_async()
            data_to_export = {
                'top_clients': clients_df,
                'rfm_analysis': rfm_data.get('rfm_data', pd.DataFrame()),
                'churn_risk': churn_df
            }
            
        elif analysis_type == "operations":
            waste_data = await analytics_adapter.get_waste_and_spoilage_analysis_async(start_date, end_date)
            inventory_df = await analytics_adapter.get_inventory_turnover_analysis_async(start_date, end_date)
            suppliers_df = await analytics_adapter.get_supplier_analysis_async(start_date, end_date)
            data_to_export = {
                'waste_analysis': waste_data.get('monthly_waste', pd.DataFrame()),
                'inventory_turnover': inventory_df,
                'suppliers': suppliers_df
            }
            
        elif analysis_type == "financial":
            cash_flow_df = await analytics_adapter.get_advanced_cashflow_analysis_async(start_date, end_date)
            payment_behavior = await analytics_adapter.get_payment_behavior_analysis_async()
            profitability_df = await analytics_adapter.get_monthly_revenue_costs_async(start_date, end_date)
            data_to_export = {
                'cash_flow': cash_flow_df,
                'payment_behavior': payment_behavior.get('client_behavior', pd.DataFrame()),
                'profitability': profitability_df
            }
            
        else:
            raise HTTPException(status_code=400, detail=f"Analysis type '{analysis_type}' not supported")
        
        # Esporta in formato richiesto
        if format.lower() == "excel":
            filename = await analytics_adapter.export_analysis_to_excel_async(
                analysis_type, data_to_export
            )
            
            return APIResponse(
                success=True,
                message=f"Analysis exported successfully",
                data={
                    'filename': filename,
                    'format': 'excel',
                    'analysis_type': analysis_type
                }
            )
        else:
            # Per CSV, ritorna i dati che il frontend puÃ² convertire
            return APIResponse(
                success=True,
                message=f"Analysis data prepared for CSV export",
                data={
                    'analysis_type': analysis_type,
                    'format': 'csv',
                    'data': data_to_export
                }
            )
        
    except Exception as e:
        logger.error(f"Error exporting analysis: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error exporting analysis")

@router.get("/export/executive-report")
async def export_executive_report(
    format: str = Query("excel", description="Formato: excel, pdf"),
    include_charts: bool = Query(True, description="Includi grafici nel report")
):
    """ðŸ”¥ NUOVO: Export report executive completo"""
    try:
        # Raccoglie tutti i dati per report executive
        executive_data = await analytics_adapter.get_executive_dashboard_async()
        kpis = await analytics_adapter.get_dashboard_kpis_async()
        business_insights = await analytics_adapter.get_business_insights_summary_async()
        
        report_data = {
            'executive_summary': executive_data,
            'key_kpis': kpis,
            'business_insights': business_insights,
            'generated_at': datetime.now().isoformat(),
            'report_type': 'Executive Dashboard'
        }
        
        if format.lower() == "excel":
            filename = await analytics_adapter.export_analysis_to_excel_async(
                "executive_report", report_data
            )
            
            return APIResponse(
                success=True,
                message="Executive report exported successfully",
                data={
                    'filename': filename,
                    'format': 'excel',
                    'include_charts': include_charts
                }
            )
        else:
            return APIResponse(
                success=True,
                message="Executive report data prepared",
                data=report_data
            )
        
    except Exception as e:
        logger.error(f"Error exporting executive report: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Error exporting executive report")

# ===== ENDPOINT DI SISTEMA E UTILITIES =====

@router.get("/health")
async def analytics_health_check():
    """Health check per il sistema analytics"""
    try:
        # Test delle funzioni principali
        test_kpis = await analytics_adapter.get_dashboard_kpis_async()
        
        health_status = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'core_functions': 'operational',
            'adapter_layer': 'operational',
            'database_connection': 'operational' if test_kpis else 'degraded',
            'available_endpoints': 50,  # Aggiorna questo numero
            'new_features_active': 25   # Numero di nuove funzionalitÃ 
        }
        
        return APIResponse(
            success=True,
            message="Analytics system health check completed",
            data=health_status
        )
        
    except Exception as e:
        logger.error(f"Health check failed: {e}", exc_info=True)
        return APIResponse(
            success=False,
            message="Analytics system health check failed",
            data={
                'status': 'unhealthy',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
        )

@router.get("/features")
async def list_available_features():
    """Lista delle feature analytics disponibili con descrizioni"""
    features = {
        "core_analytics": {
            "dashboard": "Dashboard principale con KPI",
            "kpis": "Key Performance Indicators",
            "cash_flow": "Analisi flussi di cassa",
            "revenue": "Analisi fatturato e ricavi",
            "aging": "Analisi scadenze fatture",
            "overdue": "Gestione fatture scadute"
        },
        "advanced_business_intelligence": {
            "seasonality": "ðŸ”¥ Analisi stagionalitÃ  prodotti (CRITICA per frutta/verdura)",
            "waste_analysis": "ðŸ”¥ Tracciamento scarti e deterioramento",
            "inventory_turnover": "ðŸ”¥ Rotazione inventario prodotti deperibili",
            "supplier_reliability": "ðŸ”¥ Score affidabilitÃ  fornitori",
            "competitive_analysis": "ðŸ”¥ Analisi margini vs concorrenza",
            "price_trends": "ðŸ”¥ VolatilitÃ  e trend prezzi",
            "market_basket": "ðŸ”¥ Prodotti venduti insieme (cross-selling)",
            "profitability": "ðŸ”¥ Margini di profitto dettagliati"
        },
        "customer_intelligence": {
            "rfm_segmentation": "ðŸ”¥ Segmentazione RFM (Champions, At Risk, etc.)",
            "churn_analysis": "ðŸ”¥ Clienti a rischio abbandono con azioni",
            "payment_behavior": "ðŸ”¥ Comportamento pagamenti per cliente",
            "client_performance": "ðŸ”¥ Performance avanzata clienti",
            "customer_lifetime": "ðŸ”¥ Analisi ciclo di vita cliente"
        },
        "predictive_analytics": {
            "sales_forecast": "ðŸ”¥ Previsioni vendite basate su storico",
            "seasonal_forecast": "ðŸ”¥ Previsioni stagionali",
            "cash_flow_forecast": "ðŸ”¥ Forecast flussi di cassa",
            "demand_planning": "ðŸ”¥ Pianificazione domanda"
        },
        "executive_dashboards": {
            "executive_dashboard": "ðŸ”¥ Dashboard C-level con insights",
            "operations_dashboard": "ðŸ”¥ Dashboard operativa quotidiana",
            "financial_dashboard": "ðŸ”¥ Dashboard finanziario completo",
            "executive_summary": "ðŸ”¥ Riepilogo executive con azioni"
        },
        "optimization_tools": {
            "inventory_alerts": "ðŸ”¥ Alert prodotti critici",
            "payment_optimization": "ðŸ”¥ Ottimizzazione termini pagamento",
            "cross_selling": "ðŸ”¥ Raccomandazioni cross-selling",
            "competitive_opportunities": "ðŸ”¥ OpportunitÃ  competitive"
        }
    }
    
    return APIResponse(
        success=True,
        message="Analytics features catalog",
        data={
            "total_categories": len(features),
            "total_features": sum(len(category) for category in features.values()),
            "new_advanced_features": 25,
            "features": features,
            "note": "ðŸ”¥ = Nuove funzionalitÃ  specifiche per business frutta/verdura"
        }
    )

@router.get("/")
async def analytics_root():
    """Root endpoint con panoramica completa del sistema analytics"""
    
    endpoints_summary = {
        "dashboards": [
            "GET /dashboard - Dashboard principale",
            "GET /dashboard/executive - ðŸ”¥ Dashboard C-level",
            "GET /dashboard/operations - ðŸ”¥ Dashboard operativa", 
            "GET /dashboard/financial - ðŸ”¥ Dashboard finanziario"
        ],
        "business_intelligence": [
            "GET /seasonality/products - ðŸ”¥ StagionalitÃ  (ORO per frutta/verdura)",
            "GET /waste/analysis - ðŸ”¥ Analisi scarti",
            "GET /inventory/turnover - ðŸ”¥ Rotazione inventario",
            "GET /competitive/analysis - ðŸ”¥ Analisi competitiva",
            "GET /profitability/monthly - ðŸ”¥ Margini profitto"
        ],
        "customer_analytics": [
            "GET /customers/rfm - ðŸ”¥ Segmentazione RFM",
            "GET /customers/churn-risk - ðŸ”¥ Rischio abbandono",
            "GET /clients/performance - ðŸ”¥ Performance avanzata",
            "GET /payments/behavior - ðŸ”¥ Comportamento pagamenti"
        ],
        "predictive_analytics": [
            "GET /forecasting/sales - ðŸ”¥ Previsioni vendite",
            "GET /forecasting/cash-flow - ðŸ”¥ Forecast cash flow",
            "GET /seasonality/forecast - ðŸ”¥ Previsioni stagionali"
        ],
        "optimization": [
            "GET /inventory/alerts - ðŸ”¥ Alert inventario",
            "GET /market-basket/recommendations - ðŸ”¥ Cross-selling",
            "GET /payments/optimization - ðŸ”¥ Ottimizzazione pagamenti",
            "GET /competitive/opportunities - ðŸ”¥ OpportunitÃ  competitive"
        ],
        "suppliers": [
            "GET /suppliers/analysis - ðŸ”¥ Analisi fornitori",
            "GET /suppliers/reliability - ðŸ”¥ Score affidabilitÃ ",
            "GET /suppliers/top-by-cost - Top fornitori per costo"
        ],
        "exports": [
            "GET /export/analysis - Export analisi personalizzate",
            "GET /export/executive-report - ðŸ”¥ Report executive completo"
        ],
        "utilities": [
            "GET /features - Lista funzionalitÃ  disponibili",
            "GET /health - Health check sistema",
            "GET / - Questa panoramica"
        ]
    }
    
    statistics = {
        "total_endpoints": 50,
        "new_advanced_endpoints": 25,
        "business_specific_features": 15,
        "predictive_features": 5,
        "dashboard_variants": 4
    }
    
    value_proposition = {
        "before": "Sistema base con fatturato e clienti",
        "after": "Business Intelligence completa per frutta/verdura",
        "key_improvements": [
            "Analisi stagionalitÃ  per ottimizzare acquisti",
            "Tracciamento scarti per ridurre sprechi",
            "Previsioni vendite basate su AI",
            "Segmentazione clienti avanzata",
            "Ottimizzazione supply chain fornitori",
            "Raccomandazioni automatiche business"
        ],
        "estimated_roi": {
            "waste_reduction": "15-30%",
            "sales_increase": "10-20%", 
            "margin_improvement": "5-15%",
            "customer_retention": "Identificazione precoce churn"
        }
    }
    
    return APIResponse(
        success=True,
        message="FatturaAnalyzer Analytics API - Sistema completo sbloccato!",
        data={
            "welcome": "Benvenuto nel sistema Analytics COMPLETO",
            "version": "2.0 - Full Potential Unlocked",
            "endpoints_by_category": endpoints_summary,
            "statistics": statistics,
            "value_proposition": value_proposition,
            "getting_started": {
                "executive_users": "Inizia con /dashboard/executive",
                "operations_users": "Inizia con /dashboard/operations", 
                "analysts": "Esplora /seasonality/products e /waste/analysis",
                "managers": "Vedi /customers/churn-risk e /competitive/opportunities"
            },
            "note": "ðŸ”¥ = Nuove funzionalitÃ  ora finalmente accessibili!"
        }
    )
